"""
Standalone AI Chat Desktop Application - Claude-like UI
Install requirements: pip install PyQt6 requests markdown2
Run: python desktop_chat_app.py
"""

import sys
import json
import requests
import sqlite3
from datetime import datetime
from pathlib import Path
from PyQt6.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, 
                             QHBoxLayout, QTextEdit, QPushButton, QLabel, 
                             QComboBox, QLineEdit, QListWidget, QSplitter,
                             QTabWidget, QSlider, QFileDialog, QMessageBox,
                             QScrollArea, QFrame, QTextBrowser)
from PyQt6.QtCore import Qt, QThread, pyqtSignal, QTimer, QSize
from PyQt6.QtGui import QFont, QTextCursor, QPalette, QColor, QTextCharFormat, QBrush

# Database setup
DB_PATH = "chat_history.db"

def init_database():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    c.execute('''CREATE TABLE IF NOT EXISTS conversations
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  title TEXT,
                  provider TEXT,
                  model TEXT,
                  created_at TIMESTAMP,
                  updated_at TIMESTAMP)''')
    
    c.execute('''CREATE TABLE IF NOT EXISTS messages
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  conversation_id INTEGER,
                  role TEXT,
                  content TEXT,
                  timestamp TIMESTAMP,
                  FOREIGN KEY (conversation_id) REFERENCES conversations(id))''')
    
    c.execute('''CREATE TABLE IF NOT EXISTS usage_stats
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  conversation_id INTEGER,
                  provider TEXT,
                  model TEXT,
                  input_tokens INTEGER,
                  output_tokens INTEGER,
                  estimated_cost REAL,
                  timestamp TIMESTAMP,
                  FOREIGN KEY (conversation_id) REFERENCES conversations(id))''')
    
    conn.commit()
    conn.close()

# Provider configurations
PROVIDERS = {
    "ollama": {
        "name": "Ollama (Local)",
        "icon": "ü¶ô",
        "requires_api_key": False,
        "default_host": "http://localhost:11434"
    },
    "lmstudio": {
        "name": "LM Studio (Local)",
        "icon": "üéØ",
        "requires_api_key": False,
        "default_host": "http://localhost:1234"
    },
    "groq": {
        "name": "Groq",
        "icon": "‚ö°",
        "requires_api_key": True
    },
    "openai": {
        "name": "OpenAI",
        "icon": "ü§ñ",
        "requires_api_key": True
    },
    "anthropic": {
        "name": "Anthropic",
        "icon": "üîÆ",
        "requires_api_key": True
    }
}

# Reasoning models that support thinking
REASONING_MODELS = [
    "deepseek-r1",
    "o1-preview",
    "o1-mini",
    "o1",
    "qwq"
]

# API worker thread with streaming support
class APIWorker(QThread):
    chunk_received = pyqtSignal(str)  # For streaming
    thinking_chunk = pyqtSignal(str)  # For reasoning models
    finished = pyqtSignal(str, int, int)
    error = pyqtSignal(str)
    
    def __init__(self, provider, model, messages, settings):
        super().__init__()
        self.provider = provider
        self.model = model
        self.messages = messages
        self.settings = settings
        self.full_response = ""
        self.thinking_content = ""
    
    def run(self):
        try:
            if self.provider == "ollama":
                self.call_ollama_streaming()
            elif self.provider == "lmstudio":
                self.call_lmstudio_streaming()
            elif self.provider == "groq":
                self.call_groq_streaming()
            elif self.provider == "openai":
                self.call_openai_streaming()
            elif self.provider == "anthropic":
                self.call_anthropic_streaming()
            else:
                raise Exception("Unknown provider")
            
        except Exception as e:
            self.error.emit(str(e))
    
    def is_reasoning_model(self):
        return any(rm in self.model.lower() for rm in REASONING_MODELS)
    
    def call_ollama_streaming(self):
        prompt = "\n".join([f"{m['role']}: {m['content']}" for m in self.messages])
        
        response = requests.post(
            f"{self.settings['ollama_host']}/api/generate",
            json={
                "model": self.model,
                "prompt": prompt,
                "stream": True,
                "options": {
                    "temperature": self.settings['temperature'],
                    "num_predict": self.settings['max_tokens']
                }
            },
            stream=True,
            timeout=120
        )
        
        for line in response.iter_lines():
            if line:
                data = json.loads(line)
                chunk = data.get('response', '')
                if chunk:
                    self.full_response += chunk
                    self.chunk_received.emit(chunk)
                
                if data.get('done', False):
                    break
        
        self.finished.emit(self.full_response, 0, 0)
    
    def call_lmstudio_streaming(self):
        response = requests.post(
            f"{self.settings['lmstudio_host']}/v1/chat/completions",
            json={
                "model": self.model,
                "messages": self.messages,
                "temperature": self.settings['temperature'],
                "max_tokens": self.settings['max_tokens'],
                "stream": True
            },
            stream=True,
            timeout=120
        )
        
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    line = line[6:]
                    if line.strip() == '[DONE]':
                        break
                    try:
                        data = json.loads(line)
                        chunk = data['choices'][0]['delta'].get('content', '')
                        if chunk:
                            self.full_response += chunk
                            self.chunk_received.emit(chunk)
                    except:
                        pass
        
        self.finished.emit(self.full_response, 0, 0)
    
    def call_groq_streaming(self):
        response = requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {self.settings['groq_api_key']}",
                "Content-Type": "application/json"
            },
            json={
                "model": self.model,
                "messages": self.messages,
                "temperature": self.settings['temperature'],
                "max_tokens": self.settings['max_tokens'],
                "stream": True
            },
            stream=True,
            timeout=120
        )
        
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    line = line[6:]
                    if line.strip() == '[DONE]':
                        break
                    try:
                        data = json.loads(line)
                        chunk = data['choices'][0]['delta'].get('content', '')
                        if chunk:
                            self.full_response += chunk
                            self.chunk_received.emit(chunk)
                    except:
                        pass
        
        self.finished.emit(self.full_response, 0, 0)
    
    def call_openai_streaming(self):
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {self.settings['openai_api_key']}",
                "Content-Type": "application/json"
            },
            json={
                "model": self.model,
                "messages": self.messages,
                "temperature": self.settings['temperature'],
                "max_tokens": self.settings['max_tokens'],
                "stream": True
            },
            stream=True,
            timeout=120
        )
        
        in_thinking = False
        
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    line = line[6:]
                    if line.strip() == '[DONE]':
                        break
                    try:
                        data = json.loads(line)
                        choice = data['choices'][0]
                        
                        # Check for reasoning models
                        if self.is_reasoning_model() and 'delta' in choice:
                            delta = choice['delta']
                            
                            # Handle thinking content
                            if 'reasoning_content' in delta:
                                thinking = delta['reasoning_content']
                                if thinking:
                                    self.thinking_content += thinking
                                    self.thinking_chunk.emit(thinking)
                                    in_thinking = True
                            
                            # Handle regular content
                            if 'content' in delta:
                                chunk = delta['content']
                                if chunk:
                                    self.full_response += chunk
                                    self.chunk_received.emit(chunk)
                        else:
                            chunk = choice['delta'].get('content', '')
                            if chunk:
                                self.full_response += chunk
                                self.chunk_received.emit(chunk)
                    except:
                        pass
        
        self.finished.emit(self.full_response, 0, 0)
    
    def call_anthropic_streaming(self):
        response = requests.post(
            "https://api.anthropic.com/v1/messages",
            headers={
                "x-api-key": self.settings['anthropic_api_key'],
                "anthropic-version": "2023-06-01",
                "Content-Type": "application/json"
            },
            json={
                "model": self.model,
                "messages": self.messages,
                "max_tokens": self.settings['max_tokens'],
                "temperature": self.settings['temperature'],
                "stream": True
            },
            stream=True,
            timeout=120
        )
        
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith('data: '):
                    line = line[6:]
                    try:
                        data = json.loads(line)
                        if data.get('type') == 'content_block_delta':
                            chunk = data.get('delta', {}).get('text', '')
                            if chunk:
                                self.full_response += chunk
                                self.chunk_received.emit(chunk)
                    except:
                        pass
        
        self.finished.emit(self.full_response, 0, 0)

# Custom message widget
class MessageWidget(QFrame):
    def __init__(self, role, content="", provider_icon="ü§ñ", parent=None):
        super().__init__(parent)
        self.role = role
        self.content = content
        self.provider_icon = provider_icon
        self.thinking_content = ""
        
        self.setup_ui()
    
    def setup_ui(self):
        layout = QVBoxLayout(self)
        layout.setContentsMargins(0, 0, 0, 15)
        
        # Message container
        container = QFrame()
        container_layout = QVBoxLayout(container)
        container_layout.setContentsMargins(20, 15, 20, 15)
        
        if self.role == "user":
            container.setStyleSheet("""
                QFrame {
                    background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                        stop:0 #1e3a8a, stop:1 #1e40af);
                    border: 1px solid #3b82f6;
                    border-radius: 16px;
                }
            """)
            layout.setContentsMargins(50, 0, 0, 0)  # Indent from left
        else:
            container.setStyleSheet("""
                QFrame {
                    background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                        stop:0 #1f2937, stop:1 #374151);
                    border: 1px solid #4b5563;
                    border-radius: 16px;
                }
            """)
            layout.setContentsMargins(0, 0, 50, 0)  # Indent from right
        
        # Header
        header = QLabel()
        if self.role == "user":
            header.setText("üë§ You")
        else:
            header.setText(f"{self.provider_icon} Assistant")
        
        header.setStyleSheet("""
            color: #93c5fd;
            font-weight: 600;
            font-size: 13px;
            margin-bottom: 8px;
        """)
        container_layout.addWidget(header)
        
        # Thinking bubble (for reasoning models)
        self.thinking_widget = QFrame()
        thinking_layout = QVBoxLayout(self.thinking_widget)
        thinking_layout.setContentsMargins(15, 12, 15, 12)
        self.thinking_widget.setStyleSheet("""
            QFrame {
                background-color: rgba(59, 130, 246, 0.1);
                border: 1px solid rgba(59, 130, 246, 0.3);
                border-radius: 12px;
                margin-bottom: 12px;
            }
        """)
        
        thinking_header = QLabel("üí≠ Thinking...")
        thinking_header.setStyleSheet("""
            color: #60a5fa;
            font-weight: 600;
            font-size: 12px;
            margin-bottom: 6px;
        """)
        thinking_layout.addWidget(thinking_header)
        
        self.thinking_text = QTextBrowser()
        self.thinking_text.setOpenExternalLinks(False)
        self.thinking_text.setStyleSheet("""
            QTextBrowser {
                background-color: transparent;
                border: none;
                color: #93c5fd;
                font-size: 13px;
                line-height: 1.6;
            }
        """)
        self.thinking_text.setMaximumHeight(200)
        thinking_layout.addWidget(self.thinking_text)
        
        self.thinking_widget.hide()
        container_layout.addWidget(self.thinking_widget)
        
        # Content
        self.content_text = QTextBrowser()
        self.content_text.setOpenExternalLinks(True)
        self.content_text.setStyleSheet("""
            QTextBrowser {
                background-color: transparent;
                border: none;
                color: #f3f4f6;
                font-size: 14px;
                line-height: 1.7;
            }
        """)
        
        if self.content:
            self.set_content(self.content)
        
        container_layout.addWidget(self.content_text)
        
        layout.addWidget(container)
    
    def set_content(self, content):
        self.content = content
        # Convert markdown-like formatting to HTML
        html_content = self.format_content(content)
        self.content_text.setHtml(html_content)
        self.adjust_height()
    
    def append_content(self, chunk):
        self.content += chunk
        html_content = self.format_content(self.content)
        self.content_text.setHtml(html_content)
        self.adjust_height()
    
    def set_thinking(self, thinking):
        self.thinking_content = thinking
        self.thinking_widget.show()
        html_thinking = self.format_content(thinking)
        self.thinking_text.setHtml(html_thinking)
    
    def append_thinking(self, chunk):
        self.thinking_content += chunk
        self.thinking_widget.show()
        html_thinking = self.format_content(self.thinking_content)
        self.thinking_text.setHtml(html_thinking)
    
    def format_content(self, text):
        # Simple markdown-like formatting
        html = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
        
        # Code blocks
        import re
        html = re.sub(r'```(\w+)?\n(.*?)```', 
                     r'<pre style="background-color: #1e1e1e; padding: 12px; border-radius: 6px; overflow-x: auto; margin: 10px 0;"><code>\2</code></pre>', 
                     html, flags=re.DOTALL)
        
        # Inline code
        html = re.sub(r'`([^`]+)`', 
                     r'<code style="background-color: #374151; padding: 2px 6px; border-radius: 4px; font-family: monospace;">\1</code>', 
                     html)
        
        # Bold
        html = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', html)
        
        # Line breaks
        html = html.replace('\n', '<br>')
        
        return f'<div style="font-family: Inter, sans-serif;">{html}</div>'
    
    def adjust_height(self):
        doc_height = self.content_text.document().size().height()
        self.content_text.setMinimumHeight(int(doc_height) + 20)

# Main window
class ChatWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("AI Chat Assistant")
        self.setGeometry(100, 100, 1600, 1000)
        
        init_database()
        
        # State
        self.messages = []
        self.current_conversation_id = None
        self.current_provider = "ollama"
        self.current_model = ""
        self.provider_models = {}
        self.uploaded_files = []
        self.current_message_widget = None
        
        # Settings
        self.settings = {
            "ollama_host": "http://localhost:11434",
            "lmstudio_host": "http://localhost:1234",
            "groq_api_key": "",
            "openai_api_key": "",
            "anthropic_api_key": "",
            "temperature": 0.7,
            "max_tokens": 2048
        }
        
        self.setup_ui()
        self.apply_theme()
        self.fetch_models()
    
    def setup_ui(self):
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        main_layout = QHBoxLayout(central_widget)
        main_layout.setContentsMargins(0, 0, 0, 0)
        main_layout.setSpacing(0)
        
        splitter = QSplitter(Qt.Orientation.Horizontal)
        
        # Sidebar
        sidebar = self.create_sidebar()
        splitter.addWidget(sidebar)
        
        # Main content
        main_content = self.create_main_content()
        splitter.addWidget(main_content)
        
        splitter.setSizes([320, 1280])
        splitter.setStretchFactor(1, 1)
        
        main_layout.addWidget(splitter)
    
    def create_sidebar(self):
        sidebar = QFrame()
        sidebar.setMinimumWidth(300)
        sidebar.setMaximumWidth(400)
        
        layout = QVBoxLayout(sidebar)
        layout.setContentsMargins(15, 20, 15, 20)
        layout.setSpacing(15)
        
        # Title
        title = QLabel("‚öôÔ∏è Settings")
        title.setFont(QFont("Inter", 14, QFont.Weight.Bold))
        layout.addWidget(title)
        
        # New chat
        self.new_chat_btn = QPushButton("üó®Ô∏è New Chat")
        self.new_chat_btn.clicked.connect(self.new_chat)
        layout.addWidget(self.new_chat_btn)
        
        # Provider selection
        layout.addSpacing(5)
        provider_label = QLabel("AI Provider")
        provider_label.setFont(QFont("Inter", 11, QFont.Weight.Bold))
        layout.addWidget(provider_label)
        
        # Provider buttons
        for provider_id, info in PROVIDERS.items():
            btn = QPushButton(f"{info['icon']} {info['name']}")
            btn.setCheckable(True)
            btn.clicked.connect(lambda checked, p=provider_id: self.select_provider(p))
            if provider_id == self.current_provider:
                btn.setChecked(True)
            layout.addWidget(btn)
            setattr(self, f"provider_btn_{provider_id}", btn)
        
        # Model selection
        layout.addSpacing(5)
        model_header = QHBoxLayout()
        model_label = QLabel("Model")
        model_label.setFont(QFont("Inter", 11, QFont.Weight.Bold))
        model_header.addWidget(model_label)
        model_header.addStretch()
        
        self.refresh_btn = QPushButton("üîÑ")
        self.refresh_btn.setMaximumWidth(35)
        self.refresh_btn.clicked.connect(self.fetch_models)
        model_header.addWidget(self.refresh_btn)
        
        layout.addLayout(model_header)
        
        self.model_combo = QComboBox()
        self.model_combo.currentTextChanged.connect(self.on_model_changed)
        layout.addWidget(self.model_combo)
        
        self.model_status = QLabel()
        layout.addWidget(self.model_status)
        
        # Settings tabs
        layout.addSpacing(5)
        self.settings_tab = QTabWidget()
        
        # API tab
        api_widget = QWidget()
        api_layout = QVBoxLayout(api_widget)
        api_layout.setContentsMargins(10, 10, 10, 10)
        
        self.host_label = QLabel("Host:")
        api_layout.addWidget(self.host_label)
        
        self.host_input = QLineEdit()
        self.host_input.textChanged.connect(self.update_host)
        api_layout.addWidget(self.host_input)
        
        self.api_key_label = QLabel("API Key:")
        api_layout.addWidget(self.api_key_label)
        
        self.api_key_input = QLineEdit()
        self.api_key_input.setEchoMode(QLineEdit.EchoMode.Password)
        self.api_key_input.textChanged.connect(self.update_api_key)
        api_layout.addWidget(self.api_key_input)
        
        api_layout.addStretch()
        
        # Model settings tab
        params_widget = QWidget()
        params_layout = QVBoxLayout(params_widget)
        params_layout.setContentsMargins(10, 10, 10, 10)
        
        self.temp_label = QLabel(f"Temperature: {self.settings['temperature']:.2f}")
        params_layout.addWidget(self.temp_label)
        
        self.temp_slider = QSlider(Qt.Orientation.Horizontal)
        self.temp_slider.setMinimum(0)
        self.temp_slider.setMaximum(200)
        self.temp_slider.setValue(int(self.settings['temperature'] * 100))
        self.temp_slider.valueChanged.connect(self.update_temperature)
        params_layout.addWidget(self.temp_slider)
        
        self.tokens_label = QLabel(f"Max Tokens: {self.settings['max_tokens']}")
        params_layout.addWidget(self.tokens_label)
        
        self.tokens_slider = QSlider(Qt.Orientation.Horizontal)
        self.tokens_slider.setMinimum(256)
        self.tokens_slider.setMaximum(4096)
        self.tokens_slider.setSingleStep(256)
        self.tokens_slider.setValue(self.settings['max_tokens'])
        self.tokens_slider.valueChanged.connect(self.update_max_tokens)
        params_layout.addWidget(self.tokens_slider)
        
        params_layout.addStretch()
        
        self.settings_tab.addTab(api_widget, "API")
        self.settings_tab.addTab(params_widget, "Parameters")
        
        layout.addWidget(self.settings_tab)
        
        # File upload
        layout.addSpacing(5)
        file_label = QLabel("üìÅ Upload Files")
        file_label.setFont(QFont("Inter", 11, QFont.Weight.Bold))
        layout.addWidget(file_label)
        
        self.upload_btn = QPushButton("Choose File")
        self.upload_btn.clicked.connect(self.upload_file)
        layout.addWidget(self.upload_btn)
        
        self.file_status = QLabel()
        layout.addWidget(self.file_status)
        
        # History
        layout.addSpacing(5)
        history_label = QLabel("üí¨ Chat History")
        history_label.setFont(QFont("Inter", 11, QFont.Weight.Bold))
        layout.addWidget(history_label)
        
        self.history_list = QListWidget()
        self.history_list.itemClicked.connect(self.load_conversation)
        layout.addWidget(self.history_list)
        
        self.load_history()
        
        layout.addStretch()
        
        self.update_api_visibility()
        
        return sidebar
    
    def create_main_content(self):
        main_widget = QWidget()
        layout = QVBoxLayout(main_widget)
        layout.setContentsMargins(0, 0, 0, 0)
        layout.setSpacing(0)
        
        # Chat area with scroll
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarPolicy.ScrollBarAlwaysOff)
        scroll.setStyleSheet("QScrollArea { border: none; }")
        
        self.chat_container = QWidget()
        self.chat_layout = QVBoxLayout(self.chat_container)
        self.chat_layout.setContentsMargins(40, 30, 40, 30)
        self.chat_layout.setSpacing(0)
        self.chat_layout.addStretch()
        
        scroll.setWidget(self.chat_container)
        layout.addWidget(scroll)
        
        # Input area
        input_container = QFrame()
        input_container.setStyleSheet("""
            QFrame {
                background-color: #1a1a2e;
                border-top: 1px solid #374151;
                padding: 20px;
            }
        """)
        
        input_layout = QVBoxLayout(input_container)
        input_layout.setContentsMargins(40, 20, 40, 20)
        
        # Input wrapper for centering
        input_wrapper = QHBoxLayout()
        
        self.message_input = QTextEdit()
        self.message_input.setPlaceholderText("Type your message here...")
        self.message_input.setMaximumHeight(120)
        self.message_input.setMinimumHeight(60)
        self.message_input.setStyleSheet("""
            QTextEdit {
                background-color: #1e293b;
                color: #f3f4f6;
                border: 2px solid #475569;
                border-radius: 12px;
                padding: 12px 16px;
                font-size: 14px;
                font-family: Inter, sans-serif;
            }
            QTextEdit:focus {
                border: 2px solid #3b82f6;
            }
        """)
        input_wrapper.addWidget(self.message_input)
        
        self.send_btn = QPushButton("Send")
        self.send_btn.setMinimumHeight(60)
        self.send_btn.setMinimumWidth(100)
        self.send_btn.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                    stop:0 #3b82f6, stop:1 #2563eb);
                color: white;
                border: none;
                border-radius: 12px;
                font-size: 14px;
                font-weight: 600;
                font-family: Inter, sans-serif;
            }
            QPushButton:hover {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                    stop:0 #2563eb, stop:1 #1d4ed8);
            }
            QPushButton:pressed {
                background: #1e40af;
            }
            QPushButton:disabled {
                background: #475569;
            }
        """)
        self.send_btn.clicked.connect(self.send_message)
        input_wrapper.addWidget(self.send_btn)
        
        input_layout.addLayout(input_wrapper)
        
        layout.addWidget(input_container)
        
        self.display_welcome_message()
        
        return main_widget
    
    def apply_theme(self):
        self.setStyleSheet("""
            QMainWindow {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                    stop:0 #0f0f1e, stop:1 #1a1a2e);
            }
            QFrame {
                background: qlineargradient(x1:0, y1:0, x2:0, y2:1,
                    stop:0 #16213e, stop:1 #0f3460);
                border-right: 1px solid #1e3a5f;
            }
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                    stop:0 #3b82f6, stop:1 #2563eb);
                color: white;
                border: none;
                border-radius: 8px;
                padding: 10px 16px;
                font-weight: 500;
                font-size: 13px;
                font-family: Inter, sans-serif;
            }
            QPushButton:hover {
                background: qlineargradient(x1:0, y1:0, x2:1, y
